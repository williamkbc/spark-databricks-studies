# Progresso - Forma√ß√£o Spark & Databricks (OWSHq MEC)

## Informa√ß√µes
- **Curso**: frm-spark-databricks-mec (owshq-mec)
- **Repo Pessoal**: github.com/williamkbc/spark-databricks-studies
- **Repo Curso**: github.com/owshq-mec/frm-spark-databricks-mec (somente leitura)
- **Ambiente**: Docker com Apache Spark 3.5.1, container spark-master
- **PySpark**: `docker exec -it spark-master /opt/spark/bin/pyspark --master local[2]`
- **Dados**: `/opt/spark/work/data` (dentro do container)

---

## M√≥dulo 1 - Setup do Ambiente ‚úÖ
| PR | Tema | Status |
|----|------|--------|
| PR-1 | Instala√ß√£o via Docker | ‚úÖ Praticado |
| PR-2 | PySpark Shell | ‚úÖ Praticado |
| PR-3 | Spark Submit | ‚úÖ Praticado |
| PR-4 a PR-7 | Docker Setup | ‚úÖ Praticado |

---

## M√≥dulo 2 - PySpark, Pandas API, Spark SQL

### Bloco 1: PySpark DataFrame API
| PR | Tema | Status |
|----|------|--------|
| PR-4 | Ingest√£o de Dados (JSON, Parquet, schema) | ‚úÖ Praticado |
| PR-5 | Transforma√ß√µes B√°sicas (select, filter, withColumn) | ‚úÖ Praticado |
| PR-6 | Transforma√ß√µes Complexas (groupBy, JOIN, distinct) | ‚úÖ Praticado |

### Bloco 2: Pandas API on Spark
| PR | Tema | Status |
|----|------|--------|
| PR-7 | Ingest√£o com Pandas API | ‚úÖ Praticado |
| PR-8 | Transforma√ß√µes B√°sicas Pandas API | ‚úÖ Praticado |
| PR-9 | Transforma√ß√µes Complexas Pandas API | ‚úÖ Praticado |
| PR-10 | Data Delivery Pandas API | ‚úÖ Praticado |
| PR-11 | Avan√ßado: GroupBy, Merge, Rank, Shift | ‚úÖ Praticado |
| PR-12 | UDFs, Lazy/Eager, Workarounds | ‚úÖ Praticado |
| PR-13 | Data Delivery (CSV, Parquet, particionamento) | ‚úÖ Praticado |

### Bloco 3: Spark SQL
| PR | Tema | Status |
|----|------|--------|
| PR-14 | Ingestion: Views, Tables, Catalog | ‚úÖ Praticado |
| PR-15 | Transforma√ß√µes: SELECT, WHERE, GROUP BY | ‚úÖ Praticado |
| PR-16 | Avan√ßado: Window Functions, CTEs | ‚úÖ Praticado |
| PR-17 | UDFs, PERCENTILE, STDDEV, PIVOT | ‚úÖ Praticado |
| PR-18 | Tabelas Permanentes, Particionamento, Medallion | ‚úÖ Praticado |
| PR-19 | Performance: PySpark vs SQL (Catalyst Optimizer) | ‚úÖ Praticado |

### Bloco 4: Integra√ß√µes e Arquitetura
| PR | Tema | Status |
|----|------|--------|
| PR-20 | Spark + PostgreSQL (JDBC) | üìñ S√≥ markdown (precisa PostgreSQL) |
| PR-21 | Spark + Object Storage (S3/MinIO) | üìñ S√≥ markdown (precisa MinIO) |
| PR-22 | Design Patterns (Singleton, Strategy, Factory) | ‚ö†Ô∏è S√≥ markdown - PRATICAR |
| PR-23 | Pipeline End-to-End com testes | ‚ö†Ô∏è S√≥ markdown - PRATICAR |
| PR-24 | Migra√ß√£o Pandas ‚Üí Pandas API | ‚ö†Ô∏è S√≥ markdown - PRATICAR |

### Bloco 5: Consolida√ß√£o e Deep Dive
| PR | Tema | Status |
|----|------|--------|
| PR-25 | Spark SQL como ferramenta principal | ‚ö†Ô∏è S√≥ markdown - PRATICAR |
| PR-26 | Pipeline com Error Handling e Retry | ‚ö†Ô∏è S√≥ markdown - PRATICAR |
| PR-27 | Pipeline Pandas API otimizado | ‚ö†Ô∏è S√≥ markdown - PRATICAR |
| PR-28 | SQL End-to-End modular (.sql files) | ‚ö†Ô∏è S√≥ markdown - PRATICAR |
| PR-29 | PySpark: 5 S's, Broadcast, Salting, Pitfalls | ‚ö†Ô∏è S√≥ markdown - PRATICAR |
| PR-30 | Pandas API Deep Dive | ‚ö†Ô∏è S√≥ markdown - PRATICAR |
| PR-31 | Spark SQL Deep Dive: Joins, CUBE, ROLLUP | ‚ö†Ô∏è S√≥ markdown - PRATICAR |

---

## M√≥dulo 3 - Databricks
| PR | Tema | Status |
|----|------|--------|
| - | Pendente | ‚è≥ N√£o iniciado |

---

## Legenda
- ‚úÖ Praticado: Executei comandos no PySpark e vi resultados
- üìñ S√≥ markdown: Conceitual, precisa infra adicional
- ‚ö†Ô∏è S√≥ markdown - PRATICAR: Tem conte√∫do pr√°tico mas n√£o executei ainda
- ‚è≥ N√£o iniciado

## Pr√≥ximos Passos
1. Assistir aulas do curso (PRs 22-31)
2. Praticar PRs marcados com ‚ö†Ô∏è no PySpark
3. Focar em: Broadcast Joins, CUBE/ROLLUP, Cache, Explain plans
4. Iniciar M√≥dulo 3 (Databricks)

## Prioridade de Pr√°tica
Os PRs mais importantes pra praticar (conceitos que caem em entrevista):
1. **PR-29**: 5 S's de otimiza√ß√£o, broadcast join vs sort merge
2. **PR-31**: CUBE, ROLLUP, Join Strategies, CACHE TABLE
3. **PR-28**: SQL modular com CTEs encadeadas
4. **PR-26**: Error handling com decorators
5. **PR-22**: Design patterns aplicados a pipelines
